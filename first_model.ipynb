{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRAPPIST-1e' 'PSO J318.5-22' '55 Cancri e' nan]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  \\\n",
       "0        0001_01         0.0          0          0.0  39.0    0          0.0   \n",
       "1        0002_01         1.0          0          0.0  24.0    0        109.0   \n",
       "2        0003_01         0.0          0          0.0  58.0    1         43.0   \n",
       "3        0003_02         0.0          0          0.0  33.0    0          0.0   \n",
       "4        0004_01         1.0          0          0.0  16.0    0        303.0   \n",
       "...          ...         ...        ...          ...   ...  ...          ...   \n",
       "8688     9276_01         0.0          0          2.0  41.0    1          0.0   \n",
       "8689     9278_01         1.0          1          1.0  18.0    0          0.0   \n",
       "8690     9279_01         1.0          0          0.0  26.0    0          0.0   \n",
       "8691     9280_01         0.0          0          2.0  32.0    0          0.0   \n",
       "8692     9280_02         0.0          0          0.0  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck               Name  Transported  \\\n",
       "0           0.0           0.0     0.0     0.0    Maham Ofracculy            0   \n",
       "1           9.0          25.0   549.0    44.0       Juanna Vines            1   \n",
       "2        3576.0           0.0  6715.0    49.0      Altark Susent            0   \n",
       "3        1283.0         371.0  3329.0   193.0       Solam Susent            0   \n",
       "4          70.0         151.0   565.0     2.0  Willy Santantines            1   \n",
       "...         ...           ...     ...     ...                ...          ...   \n",
       "8688     6819.0           0.0  1643.0    74.0  Gravior Noxnuther            0   \n",
       "8689        0.0           0.0     0.0     0.0    Kurta Mondalley            0   \n",
       "8690        0.0        1872.0     1.0     0.0       Fayey Connon            1   \n",
       "8691     1049.0           0.0   353.0  3235.0   Celeon Hontichre            0   \n",
       "8692     4688.0           0.0     0.0    12.0   Propsh Hontichre            1   \n",
       "\n",
       "      Deck   Num  Side  \n",
       "0      1.0     0   0.0  \n",
       "1      5.0     0   1.0  \n",
       "2      0.0     0   1.0  \n",
       "3      0.0     0   1.0  \n",
       "4      5.0     1   1.0  \n",
       "...    ...   ...   ...  \n",
       "8688   0.0    98   0.0  \n",
       "8689   6.0  1499   1.0  \n",
       "8690   6.0  1500   1.0  \n",
       "8691   4.0   608   1.0  \n",
       "8692   4.0   608   1.0  \n",
       "\n",
       "[8693 rows x 16 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CryoSleep and VIP = boolean\n",
    "#destination and home planet = groups\n",
    "#cabin needs to be split into 3 separate columns\n",
    "print(training_data['Destination'].unique())\n",
    "'''training_data['CryoSleep'] = training_data['CryoSleep'].map({'True': 1, 'False': 0})\n",
    "training_data['VIP'] = training_data['VIP'].map({'True': 1, 'False': 0})\n",
    "'''\n",
    "training_data['HomePlanet'] = training_data['HomePlanet'].map({'Europa': 0, 'Earth': 1, 'Mars':2})\n",
    "training_data['Destination'] = training_data['Destination'].map({'TRAPPIST-1e': 0, 'PSO J318.5-22': 1, '55 Cancri e':2})\n",
    "training_data[['Deck', 'Num', 'Side']] = training_data['Cabin'].str.split('/', expand=True)\n",
    "training_data = training_data.drop(columns=['Cabin'])\n",
    "deck_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}\n",
    "training_data['Deck'] = training_data['Deck'].map(deck_map)\n",
    "training_data['Side'] = training_data['Side'].map({'P': 0, 'S': 1})\n",
    "training_data['CryoSleep'] = training_data['CryoSleep'].fillna(False).astype(int)\n",
    "training_data['VIP'] = training_data['VIP'].fillna(False).astype(int)\n",
    "training_data['Transported'] = training_data['Transported'].fillna(False).astype(int)\n",
    "\n",
    "\n",
    "training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "deck_encoder = OrdinalEncoder()\n",
    "side_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  \\\n",
       "0        0001_01         0.0          0          0.0  39.0    0          0.0   \n",
       "1        0002_01         1.0          0          0.0  24.0    0        109.0   \n",
       "2        0003_01         0.0          0          0.0  58.0    1         43.0   \n",
       "3        0003_02         0.0          0          0.0  33.0    0          0.0   \n",
       "4        0004_01         1.0          0          0.0  16.0    0        303.0   \n",
       "...          ...         ...        ...          ...   ...  ...          ...   \n",
       "8688     9276_01         0.0          0          2.0  41.0    1          0.0   \n",
       "8689     9278_01         1.0          1          1.0  18.0    0          0.0   \n",
       "8690     9279_01         1.0          0          0.0  26.0    0          0.0   \n",
       "8691     9280_01         0.0          0          2.0  32.0    0          0.0   \n",
       "8692     9280_02         0.0          0          0.0  44.0    0        126.0   \n",
       "\n",
       "      FoodCourt  ShoppingMall     Spa  VRDeck               Name  Transported  \\\n",
       "0           0.0           0.0     0.0     0.0    Maham Ofracculy            0   \n",
       "1           9.0          25.0   549.0    44.0       Juanna Vines            1   \n",
       "2        3576.0           0.0  6715.0    49.0      Altark Susent            0   \n",
       "3        1283.0         371.0  3329.0   193.0       Solam Susent            0   \n",
       "4          70.0         151.0   565.0     2.0  Willy Santantines            1   \n",
       "...         ...           ...     ...     ...                ...          ...   \n",
       "8688     6819.0           0.0  1643.0    74.0  Gravior Noxnuther            0   \n",
       "8689        0.0           0.0     0.0     0.0    Kurta Mondalley            0   \n",
       "8690        0.0        1872.0     1.0     0.0       Fayey Connon            1   \n",
       "8691     1049.0           0.0   353.0  3235.0   Celeon Hontichre            0   \n",
       "8692     4688.0           0.0     0.0    12.0   Propsh Hontichre            1   \n",
       "\n",
       "      Deck   Num  Side  \n",
       "0      1.0     0   0.0  \n",
       "1      5.0     0   1.0  \n",
       "2      0.0     0   1.0  \n",
       "3      0.0     0   1.0  \n",
       "4      5.0     1   1.0  \n",
       "...    ...   ...   ...  \n",
       "8688   0.0    98   0.0  \n",
       "8689   6.0  1499   1.0  \n",
       "8690   6.0  1500   1.0  \n",
       "8691   4.0   608   1.0  \n",
       "8692   4.0   608   1.0  \n",
       "\n",
       "[8693 rows x 16 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Deck'] = deck_encoder.fit_transform(training_data[['Deck']])\n",
    "training_data['Side'] = side_encoder.fit_transform(training_data[['Side']])\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Num</th>\n",
       "      <th>Side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  FoodCourt  \\\n",
       "0            0.0          0          0.0  39.0    0          0.0        0.0   \n",
       "1            1.0          0          0.0  24.0    0        109.0        9.0   \n",
       "2            0.0          0          0.0  58.0    1         43.0     3576.0   \n",
       "3            0.0          0          0.0  33.0    0          0.0     1283.0   \n",
       "4            1.0          0          0.0  16.0    0        303.0       70.0   \n",
       "...          ...        ...          ...   ...  ...          ...        ...   \n",
       "8688         0.0          0          2.0  41.0    1          0.0     6819.0   \n",
       "8689         1.0          1          1.0  18.0    0          0.0        0.0   \n",
       "8690         1.0          0          0.0  26.0    0          0.0        0.0   \n",
       "8691         0.0          0          2.0  32.0    0          0.0     1049.0   \n",
       "8692         0.0          0          0.0  44.0    0        126.0     4688.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Deck   Num  Side  \n",
       "0              0.0     0.0     0.0   1.0     0   0.0  \n",
       "1             25.0   549.0    44.0   5.0     0   1.0  \n",
       "2              0.0  6715.0    49.0   0.0     0   1.0  \n",
       "3            371.0  3329.0   193.0   0.0     0   1.0  \n",
       "4            151.0   565.0     2.0   5.0     1   1.0  \n",
       "...            ...     ...     ...   ...   ...   ...  \n",
       "8688           0.0  1643.0    74.0   0.0    98   0.0  \n",
       "8689           0.0     0.0     0.0   6.0  1499   1.0  \n",
       "8690        1872.0     1.0     0.0   6.0  1500   1.0  \n",
       "8691           0.0   353.0  3235.0   4.0   608   1.0  \n",
       "8692           0.0     0.0    12.0   4.0   608   1.0  \n",
       "\n",
       "[8693 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = training_data['Transported']\n",
    "training_data = training_data.drop(columns=['Transported', 'PassengerId','Name'])\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(random_state=42)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features  = training_data.columns.tolist()\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "X_train_imputed = imputer.fit_transform(training_data)\n",
    "\n",
    "X_imputed_df = pd.DataFrame(X_train_imputed, columns=features)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), features)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "processed_data = preprocessor.fit_transform(X_imputed_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data, target, test_size=0.1, random_state=42, shuffle=False)\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.8149\n",
      "Precision: 0.7816\n",
      "Recall: 0.8374\n",
      "F1 Score: 0.8086\n",
      "Confusion Matrix:\n",
      " [[369  95]\n",
      " [ 66 340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "# Convert predictions to 0/1 if needed\n",
    "def test(y_pred, y_test):\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # ✅ If shape is (n_samples, 1), flatten it to (n_samples,)\n",
    "    if y_pred.ndim > 1:\n",
    "        y_pred = y_pred.ravel()\n",
    "\n",
    "    # ✅ Only threshold if values are probabilities (i.e. float)\n",
    "    if y_pred.dtype != int and y_pred.dtype != np.int64:\n",
    "        y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "    np_y_test = np.array(y_test)\n",
    "    print(np.unique(np_y_test), np_y_test.dtype)\n",
    "    print(np.unique(y_pred), y_pred.dtype)\n",
    "\n",
    "\n",
    "    acc = accuracy_score(np_y_test, y_pred)\n",
    "    prec = precision_score(np_y_test, y_pred)\n",
    "    rec = recall_score(np_y_test, y_pred)\n",
    "    f1 = f1_score(np_y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(np_y_test, y_pred))\n",
    "\n",
    "test(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def find_best_model_prediction(X_all, y_all):\n",
    "    numeric_features = X_all.columns.tolist()\n",
    "    X_train_imputed = imputer.fit_transform(X_all)\n",
    "\n",
    "    X_imputed_df = pd.DataFrame(X_train_imputed, columns=numeric_features)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numeric_features)]\n",
    "    )\n",
    "\n",
    "    processed_data = preprocessor.fit_transform(X_imputed_df)\n",
    "\n",
    "    models = {\n",
    "        \"GradientBoostingClassifier\": (\n",
    "            GradientBoostingClassifier(random_state=42),\n",
    "            {\n",
    "                'n_estimators': [100,200],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.05, 0.01],\n",
    "                'min_samples_split': [2,5],\n",
    "                'min_samples_leaf': [1,3],\n",
    "                'subsample': [0.6],\n",
    "                'max_features': ['sqrt']\n",
    "            }\n",
    "        ),\n",
    "        \"HistGradientBoosting\": (\n",
    "            HistGradientBoostingClassifier(random_state=42, early_stopping=True, validation_fraction=0.1, n_iter_no_change=10),\n",
    "            {\n",
    "                'max_iter': [100,200],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.05, 0.01],\n",
    "                'min_samples_leaf': [10, 20, 30],\n",
    "                'l2_regularization': [0.1, 0.5]\n",
    "            }\n",
    "        ),\n",
    "        \"RandomForest\": (\n",
    "            RandomForestClassifier(random_state=42),\n",
    "            {\n",
    "                'n_estimators': [100,200],\n",
    "                'max_depth': [10, 15],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [5, 3],\n",
    "                'max_features': ['sqrt']\n",
    "            }\n",
    "        ),\n",
    "        \"MLPClassifier\": (\n",
    "            MLPClassifier(random_state=42, max_iter=5000,early_stopping=True,validation_fraction=0.1, n_iter_no_change=10),\n",
    "            {\n",
    "                'hidden_layer_sizes': [(50, 50)],\n",
    "                'activation': ['relu'],\n",
    "                'learning_rate_init': [0.001, 0.01],\n",
    "                'learning_rate': [ 'adaptive'],\n",
    "                'solver': ['adam'],\n",
    "                'alpha': [ 0.01,0.1]\n",
    "            }\n",
    "        ),\n",
    "        \"XGBoost\": (\n",
    "            XGBClassifier(random_state=42, verbosity=0 ),\n",
    "            {\n",
    "                'n_estimators': [100,200],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.05, 0.01],\n",
    "                'subsample': [0.6, 0.8],\n",
    "                'reg_alpha': [0.1, 0.5],\n",
    "                'min_child_weight': [3,5],\n",
    "                'gamma': [0.1, 0.3],\n",
    "                'colsample_bytree': [0.8, 1]\n",
    "            }\n",
    "        ),\n",
    "        \"Catboost\":(\n",
    "            CatBoostClassifier(verbose=0, random_state=42),\n",
    "            {\n",
    "                'iterations': [100,200],\n",
    "                'depth': [3, 6],\n",
    "                'learning_rate': [0.05, 0.01],\n",
    "                'l2_leaf_reg': [5, 7],\n",
    "                'random_strength': [1,3],\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(processed_data, y_all, test_size=0.15, random_state=42, shuffle=True)\n",
    "    \n",
    "    results =[]\n",
    "\n",
    "    for name, (model, param_grid) in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "        grid = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy', n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters:\", grid.best_params_)\n",
    "        print(\"Best score on training data:\", grid.best_score_)\n",
    "\n",
    "        y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "        y_pred = np.round(y_pred).astype(int)\n",
    "        np_y_test = np.array(y_test).astype(int)\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "        np_y_test = np.array(y_test)\n",
    "        print(np.unique(np_y_test), np_y_test.dtype)\n",
    "        print(np.unique(y_pred), y_pred.dtype)\n",
    "\n",
    "\n",
    "        acc = accuracy_score(np_y_test, y_pred)\n",
    "        prec = precision_score(np_y_test, y_pred, pos_label=1)\n",
    "        rec = recall_score(np_y_test, y_pred, pos_label=1)\n",
    "        f1 = f1_score(np_y_test, y_pred, pos_label=1)\n",
    "\n",
    "        print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall: {rec:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(np_y_test, y_pred))\n",
    "\n",
    "        results.append({\n",
    "            'name': name,\n",
    "            'estimator': grid.best_estimator_,\n",
    "            'accuracy': acc,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred\n",
    "        })\n",
    "\n",
    "    top3 = sorted(results, key=lambda x: x['accuracy'], reverse=True)[:3]\n",
    "\n",
    "    print(\"\\n🏆 Top 3 models:\")\n",
    "    for i, result in enumerate(top3, start=1):\n",
    "        print(f\"{i}. {result['name']} - Accuracy: {result['accuracy']:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n✅ Best model: {top3[0]['name']} with Accuracy: {top3[0]['accuracy']:.4f}\")\n",
    "    return [(r['name'], r['estimator'], r['y_test'], r['y_pred']) for r in top3], preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning GradientBoostingClassifier...\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.6}\n",
      "Best score on training data: 0.8105264942011153\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7876\n",
      "Precision: 0.7681\n",
      "Recall: 0.8192\n",
      "F1 Score: 0.7928\n",
      "Confusion Matrix:\n",
      " [[497 160]\n",
      " [117 530]]\n",
      "\n",
      "Tuning HistGradientBoosting...\n",
      "Best parameters: {'l2_regularization': 0.5, 'learning_rate': 0.05, 'max_depth': 6, 'max_iter': 200, 'min_samples_leaf': 30}\n",
      "Best score on training data: 0.8093088154590505\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7952\n",
      "Precision: 0.7870\n",
      "Recall: 0.8053\n",
      "F1 Score: 0.7960\n",
      "Confusion Matrix:\n",
      " [[516 141]\n",
      " [126 521]]\n",
      "\n",
      "Tuning RandomForest...\n",
      "Best parameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score on training data: 0.8094437669891883\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7937\n",
      "Precision: 0.7779\n",
      "Recall: 0.8176\n",
      "F1 Score: 0.7973\n",
      "Confusion Matrix:\n",
      " [[506 151]\n",
      " [118 529]]\n",
      "\n",
      "Tuning MLPClassifier...\n",
      "Best parameters: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "Best score on training data: 0.8032179480954245\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7784\n",
      "Precision: 0.7625\n",
      "Recall: 0.8037\n",
      "F1 Score: 0.7825\n",
      "Confusion Matrix:\n",
      " [[495 162]\n",
      " [127 520]]\n",
      "\n",
      "Tuning XGBoost...\n",
      "Best parameters: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.5, 'subsample': 0.6}\n",
      "Best score on training data: 0.8137748590704744\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.8037\n",
      "Precision: 0.7994\n",
      "Recall: 0.8068\n",
      "F1 Score: 0.8031\n",
      "Confusion Matrix:\n",
      " [[526 131]\n",
      " [125 522]]\n",
      "\n",
      "Tuning Catboost...\n",
      "Best parameters: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.05, 'random_strength': 1}\n",
      "Best score on training data: 0.8141803549784106\n",
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7975\n",
      "Precision: 0.7771\n",
      "Recall: 0.8300\n",
      "F1 Score: 0.8027\n",
      "Confusion Matrix:\n",
      " [[503 154]\n",
      " [110 537]]\n",
      "\n",
      "🏆 Top 3 models:\n",
      "1. XGBoost - Accuracy: 0.8037\n",
      "2. Catboost - Accuracy: 0.7975\n",
      "3. HistGradientBoosting - Accuracy: 0.7952\n",
      "\n",
      "✅ Best model: XGBoost with Accuracy: 0.8037\n"
     ]
    }
   ],
   "source": [
    "top3_models, preprocessor = find_best_model_prediction(training_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def stack_models(top3_models, X_all, y_all):\n",
    "    estimators = [(name, model) for name, model, _, _ in top3_models]\n",
    "\n",
    "    # Use Logistic Regression as final estimator (you can change this)\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=RandomForestClassifier(n_estimators=100, max_depth=5),\n",
    "        passthrough=False,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Reuse X_all and y_all to fit stacked model\n",
    "    # You must reapply preprocessing to the full dataset\n",
    "    numeric_features = X_all.columns.tolist()\n",
    "    X_train_imputed = imputer.fit_transform(X_all)\n",
    "\n",
    "    X_imputed_df = pd.DataFrame(X_train_imputed, columns=numeric_features)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numeric_features)]\n",
    "    )\n",
    "\n",
    "    X_all_scaled_array = preprocessor.fit_transform(X_imputed_df)\n",
    "    X_all_scaled = pd.DataFrame(X_all_scaled_array, columns=numeric_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all_scaled, y_all, test_size=0.15, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Fit\n",
    "    stacked_model.fit(X_train, y_train)\n",
    "    y_pred = stacked_model.predict(X_test)\n",
    "\n",
    "    test(y_pred, y_test)\n",
    "    return stacked_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] int64\n",
      "[0 1] int64\n",
      "\n",
      "Accuracy: 0.7983\n",
      "Precision: 0.7824\n",
      "Recall: 0.8223\n",
      "F1 Score: 0.8018\n",
      "Confusion Matrix:\n",
      " [[509 148]\n",
      " [115 532]]\n"
     ]
    }
   ],
   "source": [
    "stacked_model = stack_models(top3_models, training_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_overall, \"best_model.pkl\")\n",
    "\n",
    "# Optionally also save the preprocessor if you need it later\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"best_model.pkl\")\n",
    "preprocessor = joblib.load(\"preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    training_data = data.copy()\n",
    "    \n",
    "    training_data['HomePlanet'] = training_data['HomePlanet'].map({'Europa': 0, 'Earth': 1, 'Mars':2})\n",
    "    training_data['Destination'] = training_data['Destination'].map({'TRAPPIST-1e': 0, 'PSO J318.5-22': 1, '55 Cancri e':2})\n",
    "    training_data[['Deck', 'Num', 'Side']] = training_data['Cabin'].str.split('/', expand=True)\n",
    "    training_data = training_data.drop(columns=['Cabin'])\n",
    "    deck_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7}\n",
    "    training_data['Deck'] = training_data['Deck'].map(deck_map)\n",
    "    training_data['Side'] = training_data['Side'].map({'P': 0, 'S': 1})\n",
    "    training_data['CryoSleep'] = training_data['CryoSleep'].fillna(False).astype(int)\n",
    "    training_data['VIP'] = training_data['VIP'].fillna(False).astype(int)\n",
    "\n",
    "    training_data = training_data.drop(columns=['Name'])\n",
    "    X_imputed = imputer.transform(training_data)\n",
    "    training_data = pd.DataFrame(X_imputed, columns=training_data.columns)\n",
    "\n",
    "    '''training_data['Deck'] = deck_encoder.transform(training_data[['Deck']])\n",
    "    training_data['Side'] = side_encoder.transform(training_data[['Side']])'''\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(data, model, preprocessor):\n",
    "    passenger_ids = data['PassengerId']\n",
    "    features = data.drop(columns=['PassengerId'])\n",
    "    run_data = clean_data(features)\n",
    "    X_test_processed = preprocessor.transform(run_data)\n",
    "    predictions = model.predict(X_test_processed)\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': passenger_ids,\n",
    "        'Transported': predictions.astype(bool)\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test.csv')\n",
    "create_submission(data,model,preprocessor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
