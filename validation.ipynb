{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tug_war_model  weighted_vote_45  weighted_vote  ensemble  \\\n",
      "PassengerId                                                             \n",
      "0013_01               True              True           True      True   \n",
      "0018_01              False             False          False     False   \n",
      "0019_01               True              True           True      True   \n",
      "0021_01               True              True           True      True   \n",
      "0023_01               True              True          False      True   \n",
      "\n",
      "             majority_vote_V3  majority_vote_V2  majority_vote  submission2  \\\n",
      "PassengerId                                                                   \n",
      "0013_01                  True              True           True         True   \n",
      "0018_01                 False             False          False        False   \n",
      "0019_01                  True              True           True         True   \n",
      "0021_01                  True              True           True         True   \n",
      "0023_01                 False              True           True         True   \n",
      "\n",
      "             submission1  \n",
      "PassengerId               \n",
      "0013_01             True  \n",
      "0018_01            False  \n",
      "0019_01             True  \n",
      "0021_01             True  \n",
      "0023_01             True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "tug_war_model: 79.8\n",
    "submission_weighted_vote_45: 80.3\n",
    "submission_weighted_vote: 79.9\n",
    "ensemble_submission: 79.8\n",
    "submission_majority_vote_V3: 79.5\n",
    "submission_majority_vote_V2: 80.2\n",
    "submission_majority_vote: 80.5\n",
    "submission_2: 80\n",
    "submission_1: 79.8\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# List your submission files and a short model name for each\n",
    "files_and_names = {\n",
    "    'tug_war_model.csv': 'tug_war_model',\n",
    "    'submission_weighted_vote_45.csv': 'weighted_vote_45',\n",
    "    'submission_weighted_vote.csv': 'weighted_vote',\n",
    "    'ensemble_submission.csv': 'ensemble',\n",
    "    'submission_majority_vote_V3.csv': 'majority_vote_V3',\n",
    "    'submission_majority_vote_V2.csv': 'majority_vote_V2',\n",
    "    'submission_majority_vote.csv': 'majority_vote',\n",
    "    'submission2.csv': 'submission2',\n",
    "    'submission1.csv': 'submission1',\n",
    "}\n",
    "\n",
    "# Initialize empty DataFrame for merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "for filename, model_name in files_and_names.items():\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Normalize 'Transported' column to boolean if not already\n",
    "    # If already bool or 0/1, this will work fine:\n",
    "    df['Transported'] = df['Transported'].astype(bool)\n",
    "    \n",
    "    # Rename the Transported column to the model name\n",
    "    df = df.rename(columns={'Transported': model_name})\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        merged_df = df.set_index('PassengerId')\n",
    "    else:\n",
    "        merged_df = merged_df.join(df.set_index('PassengerId'), how='outer')\n",
    "\n",
    "# merged_df now has one column per model with boolean predictions indexed by PassengerId\n",
    "print(merged_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with full agreement across all models: 3882\n",
      "Number of passengers with full agreement percentage: 0.908\n"
     ]
    }
   ],
   "source": [
    "# Check if all predictions in each row are equal\n",
    "all_agree = merged_df.nunique(axis=1) == 1  # True if only 1 unique value in the row\n",
    "\n",
    "# Count how many rows have complete agreement\n",
    "num_all_agree = all_agree.sum()\n",
    "avg = num_all_agree/len(merged_df)\n",
    "\n",
    "print(f\"Number of passengers with full agreement across all models: {num_all_agree}\")\n",
    "print(f\"Number of passengers with full agreement percentage: {avg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator accuracies: [0.97474865 0.97778817 0.97545008 0.98784195 0.97545008 0.97638532\n",
      " 0.97708674 0.97919102 0.95955109]\n",
      "Annotator probs: 0.534720598614876\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dawid_skene(df, max_iter=100, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Dawid-Skene for binary labels.\n",
    "\n",
    "    df: pd.DataFrame with shape (n_items, n_annotators), values 0/1.\n",
    "    Returns: estimated true labels probabilities, annotator accuracies.\n",
    "    \"\"\"\n",
    "\n",
    "    data = df.values\n",
    "    n_items, n_annotators = data.shape\n",
    "\n",
    "    # Initialize true label probabilities using majority vote\n",
    "    p_true = data.mean(axis=1)\n",
    "\n",
    "    # Initialize annotator accuracies to 0.8\n",
    "    pi = np.full(n_annotators, 0.8)\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        p_true_prev = p_true.copy()\n",
    "\n",
    "        # E-step: estimate posterior probabilities of true label = 1\n",
    "        # For each item, compute P(z_i=1 | labels, pi) proportional to:\n",
    "        #   P(labels | z_i=1) * P(z_i=1)\n",
    "        # Assuming P(z_i=1) ~ p_true[i] and independent annotators:\n",
    "\n",
    "        likelihood_true = np.ones(n_items)\n",
    "        likelihood_false = np.ones(n_items)\n",
    "\n",
    "        for j in range(n_annotators):\n",
    "            # P(label_j | z=1) = pi_j if label_j=1 else 1 - pi_j\n",
    "            likelihood_true *= np.where(data[:, j] == 1, pi[j], 1 - pi[j])\n",
    "\n",
    "            # P(label_j | z=0) = 1 - pi_j if label_j=1 else pi_j\n",
    "            likelihood_false *= np.where(data[:, j] == 1, 1 - pi[j], pi[j])\n",
    "\n",
    "        # Posterior probability of true label = 1 for each item:\n",
    "        numerator = likelihood_true * p_true\n",
    "        denominator = numerator + likelihood_false * (1 - p_true)\n",
    "        p_true = numerator / denominator\n",
    "\n",
    "        # M-step: update annotator accuracies\n",
    "        for j in range(n_annotators):\n",
    "            # Expected accuracy:\n",
    "            # Sum over items: P(z=label_j) / total items\n",
    "            correct_probs = p_true * (data[:, j] == 1) + (1 - p_true) * (data[:, j] == 0)\n",
    "            pi[j] = correct_probs.sum() / n_items\n",
    "\n",
    "        # Check convergence\n",
    "        diff = np.abs(p_true - p_true_prev).max()\n",
    "        if diff < tol:\n",
    "            break\n",
    "\n",
    "    # Final binary labels by threshold 0.5\n",
    "    labels = p_true >= 0.5\n",
    "\n",
    "    return labels, p_true, pi\n",
    "\n",
    "# Example usage:\n",
    "# Convert True/False to 1/0:\n",
    "binary_df = merged_df.astype(int)\n",
    "\n",
    "estimated_labels, prob_true, annotator_accs = dawid_skene(binary_df)\n",
    "\n",
    "# Add results back to dataframe if you want:\n",
    "df['estimated_label'] = estimated_labels\n",
    "df['prob_true'] = prob_true\n",
    "\n",
    "print(\"Annotator accuracies:\", annotator_accs)\n",
    "print(\"Annotator probs:\", (df['prob_true'].sum())/ len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId': merged_df.index,               # or use df['id'] if it's a column\n",
    "    'Transported': estimated_labels.astype(bool)  # convert 0/1 to True/False\n",
    "})\n",
    "submission.to_csv('dawid_skene_regression.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
